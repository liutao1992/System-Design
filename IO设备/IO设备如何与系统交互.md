### IO设备

I/O对计算机系统非常重要。设想一个程序没有任何输入（每次运行总会产生相同的结果），或者一个程序没有任何输出（为什么要运行它？）。显而易见，为了让计算机系统更有趣，输入和输出都是需要的。因此，常见的问题如下。

> 如何与系统交互? IO应该如何集成进系统中？其中的一般机制是什么？如何让他们变得高效？

#### 系统架构

开始讨论之前，我们先看一个典型系统的架构:

![典型系统的架构](./image/原形系统架构.png)

1. CPU通过某种内存总线（memorybus）或互连电缆连接到系统内存。
2. 图像或者其他高性能I/O设备通过常规的I/O总线（I/Obus）连接到系统，在许多现代系统中会是PCI或它的衍生形式。
3. 最后，更下面是外围总线（peripheralbus），比如SCSI、SATA或者USB。它们将最慢的设备连接到系统，包括磁盘、鼠标及其他类似设备。

> 为何要这样分层架构？

简单回答：因为物理布局及造价成本。`越快的总线越短`，因此高性能的内存总线没有足够的空间连接太多设备。另外，在工程上高性能总线的造价非常高。所以，系统的设计采用了这种分层的方式，这样可以让要求高性能的设备（比如显卡）离CPU更近一些，低性能的设备离CPU远一些。将磁盘和其他低速设备连到外围总线的好处很多，`其中较为突出的好处就是你可以在外围总线上连接大量的设备`。

![现代系统架构](./image/现代系统架构.png)

当然，现代系统越来越多地使用专门的芯片组和更快的点对点互连来提高性能。

现代系统架构显示了英特尔Z270芯片组的大致示意图，根据其架构，我们可以看到在顶部，CPU与内存系统连接最紧密，同时也与显卡(也就是显示器)有高性能连接，以支持游戏和其他图形密集型应用程序。

CPU通过英特尔专有DMI连接到I/O芯片，其余的设备通过许多不同的连接线（interconnects）连接到这个芯片。在右侧，一个或多个硬盘通过`eSATA接口`与系统相连；在图左侧，其他高性能设备则通过`PCIe`进行连接，在这个示意图中，我们可以看到网络接口以及其他高性能存储设备也在这连接。


#### 标准设备

现在来看一个标准设备（不是真实存在的），通过它来帮助我们更好地理解设备交互的机制。

![现代系统架构](./image/%E6%A0%87%E5%87%86%E8%AE%BE%E5%A4%87.png)

可以看到一个包含两部分重要组件的设备。第一部分是`向系统其他部分展现的硬件接口`。同软件一样，硬件也需要一些接口，`让系统软件来控制它的操作`。因此，所有设备都有自己的特定接口以及典型交互的协议。

第二部分是内部结构：包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备会包含简单的CPU、一些通用内存、设备相关的特定芯片，来完成它们的工作。

#### 标准协议

一个（简化的）设备接口包含3个寄存器：
1. 一个`状态（status）寄存器`，可以读取并查看设备的当前状态；
2. 一个`命令（command）寄存器`，用于通知设备执行某个具体任务；
3. 一个`数据（data）寄存器`，将数据传给设备或从设备接收数据。

通过读写这些寄存器，操作系统可以控制设备的行为。我们现在来`描述操作系统与该设备的典型交互`，以便让设备为它做某事。协议如下：

![标准协议](./image/%E6%A0%87%E5%87%86%E5%8D%8F%E8%AE%AE.png)

该协议包含4步:

1. 操作系统通过反复读取状态寄存器，等待设备进入可以接收命令的就绪状态。我们称之为轮询（polling）设备（基本上，就是问它正在做什么）。
2. 操作系统下发数据到数据寄存器。例如，你可以想象如果这是一个磁盘，需要多次写入操作，将一个磁盘块（比如4KB）传递给设备。如果主CPU参与数据移动（就像这个示例协议一样），我们就称之为编程的I/O（programmedI/O，PIO）。
3. 操作系统将命令写入命令寄存器；这样设备就知道数据已经准备好了，它应该开始执行命令。
4. 最后一步，操作系统再次通过不断轮询设备，等待并判断设备是否执行完成命令（有可能得到一个指示成功或失败的错误码）

> 该协议存在哪些问题？

我们注意到这个协议存在的第一个问题就是`轮询过程比较低效，在等待设备执行完成命令时浪费大量CPU时间`，如果此时操作系统可以切换执行下一个就绪进程，就可以大大提高CPU的利用率。

> 如何减少轮询开销？操作系统检查设备状态时如何避免频繁轮询，从而降低管理设备的CPU开销？

#### 利用中断减少CPU开销

多年前，工程师们发明了我们目前已经很常见的中断（interrupt）来减少CPU开销。有了中断后，`CPU不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发CPU跳转执行操作系统预先定义好的中断服务例程`，或更为简单的中断处理程序。中断处理程序是一小段操作系统代码，它会结束之前的请求（比如从设备读取到了数据或者错误码）并且唤醒等待I/O的进程继续执行。

因此，中断允许计算与I/O重叠（overlap），这是提高CPU利用率的关键。下面的时间线展示了这一点：

![等待IO](./image/%E7%AD%89%E5%BE%85IO.png)

其中，进程1在CPU上运行一段时间（对应CPU那一行上重复的1），然后发出一个读取数据的I/O请求给磁盘。`如果没有中断，那么操作系统就会简单自旋，不断轮询设备状态，直到设备完成I/O操作（对应其中的p）`。当设备完成请求的操作后，进程1又可以继续运行。如果我们利用中断并允许重叠，操作系统就可以在等待磁盘操作时做其他事情：

![等待IO](./image/等待IO2.png)

在这个例子中，在磁盘处理进程1的请求时，操作系统在CPU上运行进程2。磁盘处理完成后，触发一个中断，然后操作系统唤醒进程1继续运行。这样，在这段时间，无论CPU还是磁盘都可以有效地利用。

>注意，使用中断并非总是最佳方案。假如有一个非常高性能的设备，它处理请求很快：通常在CPU第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：`切换到其他进程，处理中断，再切换回之前的进程代价不小`。因此，如果设备非常快，那么最好的办法反而是轮询。如果设备比较慢，那么采用允许发生重叠的中断更好。如果设备的速度未知，或者时快时慢，可以考虑使用混合（hybrid）策略，先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。这种两阶段的办法可以实现两种方法的好处。 

> 总结：
`中断并非总是比PIO好`，尽管中断可以做到计算与I/O的重叠，但这`仅在慢速设备上有意义`。否则，`额外的中断处理和上下文切换的代价反而会超过其收益`。另外，如果短时间内出现大量的中断，可能会使得系统过载并且引发活锁。这种情况下，轮询的方式可以在操作系统自身的调度上提供更多的控制，反而更有效。

另一个`最好不要使用中断的场景是网络`。网络端收到大量数据包，如果每一个包都发生一次中断，那么有可能导致操作系统发生活锁，即不断处理中断而无法处理用户层的请求。








 











